{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62aebd45-6d60-4dd0-b752-d116e4665c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import sys\n",
    "import pylab as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44272375-c795-4cd9-8c14-2dda29ce9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSinewaveData(Dataset):\n",
    "\n",
    "    def __init__(self, split, seq_len = 128, T = 500, beta = 0.01):\n",
    "        assert split in {'train', 'test'}\n",
    "        self.split = split\n",
    "        self.seq_len = seq_len\n",
    "        self.beta = beta\n",
    "        self.T = T\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 10000 # ...\n",
    "\n",
    "        \n",
    "    def alphaT(self, t): \n",
    "    \talpha = 1-self.beta\n",
    "    \talphaT = alpha**(t)\n",
    "    \treturn alphaT\n",
    "    \n",
    "    def forward_noise(self, x, t):\n",
    "    \talpha_t = self.alphaT(t)\n",
    "    \t# Add Gaussian noise with mean 0 and covariance (1-alpha_t)*I to sqrt(alpha_t) * x\n",
    "    \tnoise = torch.randn(size = x.size()) * np.sqrt(1 - alpha_t)\n",
    "    \treturn (np.sqrt(alpha_t) * x) + noise\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.arange(0, 7, 7/self.seq_len)\n",
    "        random_phase = np.random.random() * 2 * np.pi \n",
    "        x = torch.sin(x + random_phase)\n",
    "        \n",
    "        # Sample number of noise steps t to apply between 1 and T\n",
    "        t = int(np.random.random() * self.T)\n",
    "        \n",
    "        # Add forward noising\n",
    "        y = self.forward_noise(x, t)\n",
    "\n",
    "        # compute the noise\n",
    "        noise = y - x\n",
    "\n",
    "        # return the noisy data and the noise in it\n",
    "        return y, noise, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7028ea3b-c9db-428f-b5f2-147c4e019d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RandomSinewaveData('train', 256)\n",
    "test_dataset = RandomSinewaveData('test', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a676178d-208a-4c16-8af1-d98e968f5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            batch_size=100,\n",
    "            num_workers=0,\n",
    "            drop_last=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db173521-aee8-46e5-a513-5c72bc8b8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    pass\n",
    "\n",
    "batch = [t.to('cpu') for t in batch]\n",
    "x, y, t = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a2f8da4-58cd-4765-97f6-752d9e452e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 256]), torch.Size([100, 256]), torch.Size([100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b637842b-f9d2-4d6b-8453-8eacd9a284b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DDPM\n",
    "model = DDPM(256, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fd24fd-3391-49fa-bb5c-92a7f0a548ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 08:12:36.964316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 08:12:37.178656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-08 08:12:37.178682: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-08 08:12:38.046047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-08 08:12:38.046123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-08 08:12:38.046131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "from trainer import Trainer\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 3e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 20000\n",
    "train_config.num_workers = 0\n",
    "train_config.batch_size = 100\n",
    "train_config.eval_iters = 100\n",
    "train_config.resume = False\n",
    "train_config.checkpoint_path = '/home/suhas/research/dl/checkpoints/'\n",
    "trainer = Trainer(train_config, model, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc9a14-0ea9-448c-b3bf-c05c3823cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_num 100  train_loss: 0.975667417049408 , test_loss:  0.9838844537734985 , last batch loss: 0.9633376598358154\n",
      "iter_num 200  train_loss: 0.9027020335197449 , test_loss:  0.9024069905281067 , last batch loss: 0.9184257984161377\n",
      "iter_num 300  train_loss: 0.9022958278656006 , test_loss:  0.9001274704933167 , last batch loss: 0.9484067559242249\n",
      "iter_num 400  train_loss: 0.8982862830162048 , test_loss:  0.8977109789848328 , last batch loss: 0.9855605363845825\n",
      "iter_num 500  train_loss: 0.8959603905677795 , test_loss:  0.9011164307594299 , last batch loss: 0.9265532493591309\n",
      "iter_num 600  train_loss: 0.8935606479644775 , test_loss:  0.8990119695663452 , last batch loss: 0.8663609027862549\n",
      "iter_num 700  train_loss: 0.9127204418182373 , test_loss:  0.9063230752944946 , last batch loss: 0.8772531747817993\n",
      "iter_num 800  train_loss: 0.8915033936500549 , test_loss:  0.8976140022277832 , last batch loss: 0.8990994095802307\n",
      "iter_num 900  train_loss: 0.8918917179107666 , test_loss:  0.892184317111969 , last batch loss: 0.9011838436126709\n",
      "iter_num 1000  train_loss: 0.9018886089324951 , test_loss:  0.8948982357978821 , last batch loss: 0.917402446269989\n",
      "iter_num 1100  train_loss: 0.8910375237464905 , test_loss:  0.8919680714607239 , last batch loss: 0.9435953497886658\n",
      "iter_num 1200  train_loss: 0.8782815337181091 , test_loss:  0.8836876749992371 , last batch loss: 0.8878791332244873\n",
      "iter_num 1300  train_loss: 0.8773964643478394 , test_loss:  0.8759095668792725 , last batch loss: 0.83479905128479\n",
      "iter_num 1400  train_loss: 0.862295389175415 , test_loss:  0.8674504160881042 , last batch loss: 0.8083804249763489\n",
      "iter_num 1500  train_loss: 0.8560052514076233 , test_loss:  0.8549812436103821 , last batch loss: 0.8485134243965149\n",
      "iter_num 1600  train_loss: 0.8506374955177307 , test_loss:  0.8512323498725891 , last batch loss: 0.8336502909660339\n",
      "iter_num 1700  train_loss: 0.8467387557029724 , test_loss:  0.8483643531799316 , last batch loss: 0.8690488934516907\n",
      "iter_num 1800  train_loss: 0.8484340906143188 , test_loss:  0.8443358540534973 , last batch loss: 0.8183560967445374\n",
      "iter_num 1900  train_loss: 0.842471718788147 , test_loss:  0.8450059294700623 , last batch loss: 0.8612831830978394\n",
      "iter_num 2000  train_loss: 0.8370009064674377 , test_loss:  0.840868353843689 , last batch loss: 0.9020176529884338\n",
      "iter_num 2100  train_loss: 0.8338009715080261 , test_loss:  0.8365311622619629 , last batch loss: 0.7942456007003784\n",
      "iter_num 2200  train_loss: 0.8279179930686951 , test_loss:  0.8315017223358154 , last batch loss: 0.8615285754203796\n",
      "iter_num 2300  train_loss: 0.8222838044166565 , test_loss:  0.8225231170654297 , last batch loss: 0.8229203820228577\n",
      "iter_num 2400  train_loss: 0.8287542462348938 , test_loss:  0.8220245242118835 , last batch loss: 0.8098370432853699\n",
      "iter_num 2500  train_loss: 0.8195838332176208 , test_loss:  0.8276340365409851 , last batch loss: 0.8468061089515686\n",
      "iter_num 2600  train_loss: 0.8107086420059204 , test_loss:  0.8109591603279114 , last batch loss: 0.7891536951065063\n",
      "iter_num 2700  train_loss: 0.8121047019958496 , test_loss:  0.8059239983558655 , last batch loss: 0.8513039946556091\n",
      "iter_num 2800  train_loss: 0.8070774674415588 , test_loss:  0.8077441453933716 , last batch loss: 0.8029812574386597\n",
      "iter_num 2900  train_loss: 0.805686891078949 , test_loss:  0.8035337924957275 , last batch loss: 0.7436032295227051\n",
      "iter_num 3000  train_loss: 0.7990516424179077 , test_loss:  0.7985700368881226 , last batch loss: 0.7719311714172363\n",
      "iter_num 3100  train_loss: 0.7940621376037598 , test_loss:  0.8004768490791321 , last batch loss: 0.7505466938018799\n",
      "iter_num 3200  train_loss: 0.7940763235092163 , test_loss:  0.7926582098007202 , last batch loss: 0.7650611996650696\n",
      "iter_num 3300  train_loss: 0.7869109511375427 , test_loss:  0.7871049642562866 , last batch loss: 0.8098477721214294\n",
      "iter_num 3400  train_loss: 0.7855972051620483 , test_loss:  0.7853557467460632 , last batch loss: 0.8406147956848145\n",
      "iter_num 3500  train_loss: 0.7885265946388245 , test_loss:  0.7906895279884338 , last batch loss: 0.7989360690116882\n",
      "iter_num 3600  train_loss: 0.7777085304260254 , test_loss:  0.7852851748466492 , last batch loss: 0.7967496514320374\n",
      "iter_num 3700  train_loss: 0.7790728211402893 , test_loss:  0.780231773853302 , last batch loss: 0.8059386610984802\n",
      "iter_num 3800  train_loss: 0.7778181433677673 , test_loss:  0.783763587474823 , last batch loss: 0.7720301747322083\n",
      "iter_num 3900  train_loss: 0.7734528183937073 , test_loss:  0.7735679745674133 , last batch loss: 0.8033177852630615\n",
      "iter_num 4000  train_loss: 0.7730525135993958 , test_loss:  0.7710462808609009 , last batch loss: 0.7701258659362793\n",
      "iter_num 4100  train_loss: 0.776212215423584 , test_loss:  0.7706578969955444 , last batch loss: 0.7866157293319702\n",
      "iter_num 4200  train_loss: 0.7735901474952698 , test_loss:  0.7646299600601196 , last batch loss: 0.8278505206108093\n",
      "iter_num 4300  train_loss: 0.7693737745285034 , test_loss:  0.7711240649223328 , last batch loss: 0.7699763774871826\n",
      "iter_num 4400  train_loss: 0.774507462978363 , test_loss:  0.769741952419281 , last batch loss: 0.7225253582000732\n",
      "iter_num 4500  train_loss: 0.7669641375541687 , test_loss:  0.7678096890449524 , last batch loss: 0.7829399108886719\n",
      "iter_num 4600  train_loss: 0.7764214873313904 , test_loss:  0.7661080956459045 , last batch loss: 0.7601407766342163\n",
      "iter_num 4700  train_loss: 0.7593073844909668 , test_loss:  0.764057993888855 , last batch loss: 0.7874442934989929\n",
      "iter_num 4800  train_loss: 0.7643441557884216 , test_loss:  0.7610978484153748 , last batch loss: 0.7616214156150818\n",
      "iter_num 4900  train_loss: 0.7573297619819641 , test_loss:  0.75823575258255 , last batch loss: 0.7834994792938232\n",
      "iter_num 5000  train_loss: 0.7616912126541138 , test_loss:  0.7601745128631592 , last batch loss: 0.7411363124847412\n",
      "iter_num 5100  train_loss: 0.7572670578956604 , test_loss:  0.7580918669700623 , last batch loss: 0.7232502102851868\n",
      "iter_num 5200  train_loss: 0.7575833201408386 , test_loss:  0.7538236975669861 , last batch loss: 0.7885616421699524\n",
      "iter_num 5300  train_loss: 0.7531057596206665 , test_loss:  0.7530738711357117 , last batch loss: 0.7993271350860596\n",
      "iter_num 5400  train_loss: 0.752573549747467 , test_loss:  0.7586318254470825 , last batch loss: 0.7671633958816528\n",
      "iter_num 5500  train_loss: 0.7565971612930298 , test_loss:  0.7487159967422485 , last batch loss: 0.7814526557922363\n",
      "iter_num 5600  train_loss: 0.7538663744926453 , test_loss:  0.7588695287704468 , last batch loss: 0.8382048010826111\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e87d5-1b02-494a-94af-8b85fa1b3e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
